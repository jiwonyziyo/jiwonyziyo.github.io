<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>HCI-Lecture on Jiwon KANG</title>
        <link>http://localhost:1313/tags/hci-lecture/</link>
        <description>Recent content in HCI-Lecture on Jiwon KANG</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Tue, 08 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/hci-lecture/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Lecture 7 - Ideate</title>
        <link>http://localhost:1313/post/ideate/ideate/</link>
        <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/ideate/ideate/</guid>
        <description></description>
        </item>
        <item>
        <title>Lecture 8 - Prototype</title>
        <link>http://localhost:1313/post/prototype/prototype/</link>
        <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/prototype/prototype/</guid>
        <description>&lt;h2 id=&#34;prototype&#34;&gt;Prototype
&lt;/h2&gt;&lt;p&gt;How you can apply the same thing this kind of prototype&lt;/p&gt;
&lt;p&gt;Heuristic evaluation - this should be done by experting fields by experts
lab experiment/ Field study/ Survey -&amp;gt; are we missing any other research methods? in physics the &amp;ldquo;똘뜨스?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;create some kind of hypothesis / it should be testable -&amp;gt; how bad or how good it is. importany to know about is variable.&lt;/p&gt;
&lt;p&gt;difference bewtween two variables woth some examples ?&lt;/p&gt;
&lt;p&gt;독립변수, 종속변수&lt;/p&gt;
&lt;p&gt;for example, imagine we work for gain the money.
in this case the independent variable is the amount of work because this variable can change ourselves.
the dependent variable is the salary. because the amount of the money we can earn is depends on the amount of work.&lt;/p&gt;
&lt;p&gt;independent variable -&amp;gt;
dependent variable -&amp;gt;
control variable -&amp;gt; which affects the dependent variables&lt;/p&gt;
&lt;p&gt;control variable -&amp;gt; ex. I drop a ball from certain height, i measure the bouncing height. (bouncing height -&amp;gt; dependent variable / certain  height -&amp;gt; indepent variable / ball(itself) or the floor -&amp;gt; control variable. )&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Lecture 4 - HCI Researcher</title>
        <link>http://localhost:1313/post/hciresearcher/researcher/</link>
        <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/hciresearcher/researcher/</guid>
        <description>&lt;img src="http://localhost:1313/images/researcher.png" alt="Featured image of post Lecture 4 - HCI Researcher" /&gt;&lt;h1 id=&#34;hci-researcher--young-ho-kim&#34;&gt;HCI Researcher : Young-Ho Kim
&lt;/h1&gt;&lt;h2 id=&#34;current-role-and-expertise&#34;&gt;Current Role and Expertise
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Young-Ho Kim&lt;/strong&gt; is a &lt;strong&gt;Lead Research Scientist at NAVER AI Lab&lt;/strong&gt; and a prominent researcher in the field of &lt;strong&gt;HCI&lt;/strong&gt;. His work spans across multiple domains, including &lt;strong&gt;Personal Health Informatics&lt;/strong&gt;, &lt;strong&gt;Ubiquitous Computing (UbiComp)&lt;/strong&gt;, and &lt;strong&gt;Personal Data Visualization&lt;/strong&gt;. By integrating his knowledge of &lt;strong&gt;computer science&lt;/strong&gt; and &lt;strong&gt;visual communication design&lt;/strong&gt;, Kim focuses on designing systems that enhance human-data interaction, especially in the context of &lt;strong&gt;self-tracking technologies&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;research-focus&#34;&gt;Research Focus
&lt;/h2&gt;&lt;p&gt;His &lt;strong&gt;current research&lt;/strong&gt; emphasizes the development of &lt;strong&gt;flexible self-tracking systems&lt;/strong&gt; that adapt to the needs, contexts, and preferences of individuals. His goal is to empower users to make informed decisions and behavioral changes through better data interaction. His approach often involves combining &lt;strong&gt;AI&lt;/strong&gt; and &lt;strong&gt;Natural Language Processing (NLP)&lt;/strong&gt; technologies, particularly &lt;strong&gt;Large Language Models (LLMs)&lt;/strong&gt;, to create &lt;strong&gt;intelligent self-trackers&lt;/strong&gt;. These systems help users better understand and reflect on their behaviors and health data in everyday contexts.&lt;/p&gt;
&lt;h2 id=&#34;recent-research-projects&#34;&gt;Recent Research Projects
&lt;/h2&gt;&lt;p&gt;One of Kim&amp;rsquo;s &lt;strong&gt;notable ongoing projects&lt;/strong&gt; includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CareCall&lt;/strong&gt;: A project designed to use LLMs for public health interventions. In this system, conversational AI assists socially isolated individuals by conducting regular check-up calls. The system not only gathers health metrics but also provides emotional support through empathetic conversations. The findings from this project highlight both the benefits and challenges of using LLM-driven systems in real-world public health contexts, such as balancing user expectations and handling the limitations of AI in personalization and memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another major project is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Textoshop&lt;/strong&gt;: A novel tool that applies concepts from image editing to text manipulation. It allows users to engage in flexible and creative text editing by treating words and sentences similarly to how designers manipulate visual elements in software like Photoshop.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;notable-contributions-and-impact-on-hci&#34;&gt;Notable Contributions and Impact on HCI
&lt;/h2&gt;&lt;p&gt;Kim&amp;rsquo;s work has significantly impacted how &lt;strong&gt;AI and human-centered design&lt;/strong&gt; are integrated into real-world applications. By designing systems that bridge the gap between humans and data, he has contributed to making &lt;strong&gt;self-tracking technologies&lt;/strong&gt; more accessible and adaptable to various user needs. His contributions to &lt;strong&gt;public health technology&lt;/strong&gt;—especially in using AI to enhance social and emotional well-being—highlight the evolving role of &lt;strong&gt;HCI&lt;/strong&gt; in addressing both technical and social challenges.&lt;/p&gt;
&lt;h3 id=&#34;key-publications&#34;&gt;Key Publications
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Understanding the Benefits and Challenges of Deploying Conversational AI Leveraging Large Language Models for Public Health Intervention&amp;rdquo;&lt;/strong&gt; (2023): This paper explores how LLM-based conversational AI systems can assist in public health interventions by monitoring and supporting socially isolated individuals.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dl.acm.org/doi/10.1145/3544548.3581503&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kim&amp;rsquo;s CareCall project paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Textoshop: Interactions Inspired by Drawing Software to Facilitate Text Editing&amp;rdquo;&lt;/strong&gt; (2024): In this paper, Kim and collaborators introduce a tool that reimagines text editing by applying principles of design software, enhancing user interaction with text through direct manipulation.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2409.17088&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Textoshop project paper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;achievements&#34;&gt;Achievements
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Best Paper Award&lt;/strong&gt; at CHI 2023&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Best of CHI Honorable Mention&lt;/strong&gt; in 2021&lt;/li&gt;
&lt;li&gt;Recipient of the &lt;strong&gt;International Postdoc Fellowship&lt;/strong&gt; from the National Research Foundation of Korea (2019)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;Young-Ho Kim&amp;rsquo;s work at the forefront of &lt;strong&gt;HCI research&lt;/strong&gt; continues to shape how we think about user interaction with data and technology. His contributions to &lt;strong&gt;flexible self-tracking systems&lt;/strong&gt; and &lt;strong&gt;AI-driven health interventions&lt;/strong&gt; exemplify the power of integrating &lt;strong&gt;advanced AI&lt;/strong&gt; with &lt;strong&gt;human-centered design&lt;/strong&gt;, making significant strides in both public health and everyday technology interactions.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Lecture 5 - Ultimate Display by Ivan Sutherland </title>
        <link>http://localhost:1313/post/readivan/ultimatedisplay/</link>
        <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/readivan/ultimatedisplay/</guid>
        <description>&lt;img src="http://localhost:1313/images/ivan.jpg" alt="Featured image of post Lecture 5 - Ultimate Display by Ivan Sutherland " /&gt;&lt;h1 id=&#34;reflections-on-ivan-sutherlands-the-ultimate-display&#34;&gt;Reflections on Ivan Sutherland&amp;rsquo;s &amp;ldquo;The Ultimate Display&amp;rdquo;
&lt;/h1&gt;&lt;p&gt;In his seminal work &lt;strong&gt;&amp;ldquo;The Ultimate Display&amp;rdquo;&lt;/strong&gt; (1965), Ivan Sutherland laid the foundation for what we now recognize as virtual and augmented reality (VR/AR). His visionary ideas foreshadowed many technologies that are prevalent today, and he also introduced concepts that continue to guide future developments in human-computer interaction and immersive experiences.&lt;/p&gt;
&lt;h2 id=&#34;current-realizations-of-sutherlands-vision&#34;&gt;Current Realizations of Sutherland’s Vision
&lt;/h2&gt;&lt;h3 id=&#34;1-virtual-reality-vr-and-augmented-reality-ar&#34;&gt;1. Virtual Reality (VR) and Augmented Reality (AR)
&lt;/h3&gt;&lt;p&gt;One of Sutherland&amp;rsquo;s most notable predictions was the creation of &lt;strong&gt;virtual worlds indistinguishable from reality&lt;/strong&gt;. He envisioned a computer-generated environment that could simulate reality with such fidelity that users would be unable to tell the difference between the virtual and the real. Today, &lt;strong&gt;VR headsets&lt;/strong&gt; like the &lt;strong&gt;Oculus Rift&lt;/strong&gt;, &lt;strong&gt;HTC Vive&lt;/strong&gt;, and &lt;strong&gt;PlayStation VR&lt;/strong&gt; offer immersive environments where users can interact with 3D worlds. &lt;strong&gt;Augmented Reality (AR)&lt;/strong&gt; systems, like those seen in &lt;strong&gt;Microsoft’s HoloLens&lt;/strong&gt; and mobile apps such as &lt;strong&gt;Pokémon Go&lt;/strong&gt;, overlay digital information onto the real world, blending the virtual with the physical.&lt;/p&gt;
&lt;h3 id=&#34;2-haptic-feedback-and-tactile-displays&#34;&gt;2. Haptic Feedback and Tactile Displays
&lt;/h3&gt;&lt;p&gt;Sutherland also imagined the possibility of interacting with virtual objects in a way that mimicked their real-world counterparts, suggesting that &amp;ldquo;a chair displayed in such a room would be good enough to sit in.&amp;rdquo; This idea has come to life through &lt;strong&gt;haptic technology&lt;/strong&gt; and &lt;strong&gt;force feedback systems&lt;/strong&gt;, which allow users to “feel” virtual objects. Today’s &lt;strong&gt;haptic gloves&lt;/strong&gt; and &lt;strong&gt;vests&lt;/strong&gt; can simulate touch, texture, and resistance, enhancing the immersive experience in virtual worlds.&lt;/p&gt;
&lt;h3 id=&#34;3-interactive-graphics-and-real-time-simulation&#34;&gt;3. Interactive Graphics and Real-Time Simulation
&lt;/h3&gt;&lt;p&gt;Sutherland&amp;rsquo;s work directly influenced the development of &lt;strong&gt;interactive computer graphics&lt;/strong&gt;. He envisioned dynamic environments where users could manipulate objects in real-time. Modern computer graphics, powered by &lt;strong&gt;game engines&lt;/strong&gt; such as &lt;strong&gt;Unreal Engine&lt;/strong&gt; and &lt;strong&gt;Unity&lt;/strong&gt;, allow for the creation of highly interactive and realistic simulations. Video games, 3D modeling software, and even training simulations for fields like medicine and aviation use these technologies.&lt;/p&gt;
&lt;h2 id=&#34;what-could-become-reality-in-the-future&#34;&gt;What Could Become Reality in the Future?
&lt;/h2&gt;&lt;h3 id=&#34;1-full-sensory-immersion&#34;&gt;1. Full Sensory Immersion
&lt;/h3&gt;&lt;p&gt;Sutherland hinted at the possibility of stimulating all human senses in virtual environments, suggesting that a truly ultimate display would engage &lt;strong&gt;sight, sound, touch, and possibly even taste and smell&lt;/strong&gt;. While current VR systems focus primarily on visual and auditory experiences, the future could see the development of technology that simulates all senses. &lt;strong&gt;Olfactory displays&lt;/strong&gt; (devices that emit smells) and &lt;strong&gt;gustatory technology&lt;/strong&gt; (taste simulation) are still in early research stages, but with advancements in neuroscience and sensory technology, a fully immersive multisensory virtual world may become possible.&lt;/p&gt;
&lt;h3 id=&#34;2-brain-computer-interfaces-bci&#34;&gt;2. Brain-Computer Interfaces (BCI)
&lt;/h3&gt;&lt;p&gt;Another aspect of Sutherland&amp;rsquo;s vision was the direct interaction between the human brain and computers. While he did not explicitly predict &lt;strong&gt;brain-computer interfaces (BCI)&lt;/strong&gt;, his ideas about creating seamless interaction between humans and machines suggest that this could be the next step. Current research into &lt;strong&gt;BCI technology&lt;/strong&gt;, such as &lt;strong&gt;Neuralink&lt;/strong&gt; by Elon Musk, explores the potential of controlling computers and virtual environments using only thoughts. This could lead to a future where users can fully immerse themselves in virtual worlds without the need for physical hardware.&lt;/p&gt;
&lt;h3 id=&#34;3-shared-virtual-worlds-and-digital-communities&#34;&gt;3. Shared Virtual Worlds and Digital Communities
&lt;/h3&gt;&lt;p&gt;Sutherland&amp;rsquo;s ultimate display also hinted at the potential for &lt;strong&gt;shared virtual experiences&lt;/strong&gt;, where multiple users could interact with each other in a virtual space. This concept is becoming a reality with the advent of &lt;strong&gt;the metaverse&lt;/strong&gt;, a digital universe where users can socialize, work, and play in a shared, persistent environment. Companies like &lt;strong&gt;Meta (formerly Facebook)&lt;/strong&gt; and &lt;strong&gt;Epic Games&lt;/strong&gt; are investing heavily in this area, aiming to create a connected virtual world where people can live out alternative realities together.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;Ivan Sutherland’s &lt;strong&gt;“The Ultimate Display”&lt;/strong&gt; was groundbreaking in its vision of a future where humans and computers interact in ways that were unimaginable at the time. Many of his predictions have become reality, including virtual environments, interactive graphics, and haptic feedback systems. His vision continues to inspire the next generation of researchers and technologists, pushing the boundaries of &lt;strong&gt;VR&lt;/strong&gt;, &lt;strong&gt;AR&lt;/strong&gt;, and &lt;strong&gt;BCI&lt;/strong&gt; technologies.&lt;/p&gt;
&lt;p&gt;As we move forward, it’s clear that Sutherland’s concept of a fully immersive, multisensory, and interactive digital world remains the ultimate goal of HCI, and his work will continue to shape the future of the field.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Source&lt;/strong&gt;: &lt;a class=&#34;link&#34; href=&#34;http://worrydream.com/refs/Sutherland%20-%20The%20Ultimate%20Display.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Ultimate Display by Ivan Sutherland&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Lecture 6 - Input Devices and Interaction Paradigm</title>
        <link>http://localhost:1313/post/devices/inputdevices/</link>
        <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/devices/inputdevices/</guid>
        <description>&lt;img src="http://localhost:1313/images/leap.jpg" alt="Featured image of post Lecture 6 - Input Devices and Interaction Paradigm" /&gt;&lt;h1 id=&#34;input-devices-and-interaction-paradigms-the-leap-motion-controller&#34;&gt;Input Devices and Interaction Paradigms: The Leap Motion Controller
&lt;/h1&gt;&lt;h2 id=&#34;overview-of-the-leap-motion-controller&#34;&gt;Overview of the Leap Motion Controller
&lt;/h2&gt;&lt;p&gt;The &lt;strong&gt;Leap Motion Controller&lt;/strong&gt;, introduced in 2013, was a &lt;strong&gt;gesture-based input device&lt;/strong&gt; that aimed to revolutionize how we interact with computers by allowing users to control on-screen elements using &lt;strong&gt;hand and finger movements&lt;/strong&gt;. Unlike traditional input devices like the mouse or keyboard, Leap Motion provided a &lt;strong&gt;touch-free, 3D interaction&lt;/strong&gt; experience. It was designed to track the movement of users’ hands in real-time, capturing detailed motions within an interaction space of about 8 cubic feet.&lt;/p&gt;
&lt;h3 id=&#34;classification-gesture-based-user-interface&#34;&gt;Classification: Gesture-Based User Interface
&lt;/h3&gt;&lt;p&gt;The Leap Motion falls under the category of &lt;strong&gt;Gesture-Based User Interface (GBUI)&lt;/strong&gt;. This type of user interface allows users to interact with a computer through body movements—specifically, hand and finger gestures. GBUI is a part of &lt;strong&gt;Natural User Interfaces (NUI)&lt;/strong&gt;, which focus on intuitive and natural interaction techniques.&lt;/p&gt;
&lt;h2 id=&#34;why-the-leap-motion-failed-to-succeed&#34;&gt;Why the Leap Motion Failed to Succeed
&lt;/h2&gt;&lt;p&gt;While Leap Motion was exciting in its innovation and garnered significant media attention upon launch, it ultimately did not achieve widespread adoption. Several reasons contribute to its failure to succeed:&lt;/p&gt;
&lt;h3 id=&#34;1-limited-use-cases&#34;&gt;1. &lt;strong&gt;Limited Use Cases&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;Although the Leap Motion device was revolutionary in concept, it struggled to find compelling real-world applications. Its primary use cases were limited to &lt;strong&gt;gaming, 3D modeling&lt;/strong&gt;, and a few experimental applications. The niche appeal of these areas limited the audience. Most users still found traditional input methods (like the mouse and keyboard) more convenient and efficient for daily tasks.&lt;/p&gt;
&lt;h3 id=&#34;2-accuracy-and-tracking-issues&#34;&gt;2. &lt;strong&gt;Accuracy and Tracking Issues&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;While Leap Motion promised precise hand tracking, many users reported &lt;strong&gt;inconsistent accuracy&lt;/strong&gt; and &lt;strong&gt;latency&lt;/strong&gt; issues, especially when their hands moved too quickly or left the designated interaction zone. This inconsistency frustrated users and made it difficult to rely on for precise tasks, such as &lt;strong&gt;3D design&lt;/strong&gt; or &lt;strong&gt;professional workflows&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;3-lack-of-developer-support&#34;&gt;3. &lt;strong&gt;Lack of Developer Support&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;The success of input devices heavily depends on third-party developer support to create applications and software that leverage the technology. In Leap Motion’s case, there was a lack of &lt;strong&gt;sufficient developer support&lt;/strong&gt; to build a robust ecosystem of applications. Many developers found the Leap Motion SDK challenging to work with, and without compelling applications, users had little incentive to adopt the device.&lt;/p&gt;
&lt;h3 id=&#34;4-competition-with-vr-and-ar-technologies&#34;&gt;4. &lt;strong&gt;Competition with VR and AR Technologies&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;At the time of its launch, &lt;strong&gt;Virtual Reality (VR)&lt;/strong&gt; and &lt;strong&gt;Augmented Reality (AR)&lt;/strong&gt; were becoming more popular, with devices like the &lt;strong&gt;Oculus Rift&lt;/strong&gt; and &lt;strong&gt;Microsoft HoloLens&lt;/strong&gt; capturing the attention of both developers and users. Leap Motion tried to pivot toward VR, offering integration with VR headsets, but it was too late to compete effectively in the growing immersive tech space.&lt;/p&gt;
&lt;h2 id=&#34;could-it-succeed-in-the-future&#34;&gt;Could It Succeed in the Future?
&lt;/h2&gt;&lt;p&gt;Though the Leap Motion Controller did not succeed in its initial form, the technology behind it could find new life in the future with advancements in &lt;strong&gt;machine learning&lt;/strong&gt; and &lt;strong&gt;computer vision&lt;/strong&gt;. Gesture-based interfaces are becoming increasingly important in &lt;strong&gt;augmented reality (AR)&lt;/strong&gt; and &lt;strong&gt;virtual reality (VR)&lt;/strong&gt; environments, where hands-free interaction is critical.&lt;/p&gt;
&lt;p&gt;For instance, Leap Motion&amp;rsquo;s acquisition by &lt;strong&gt;Ultrahaptics&lt;/strong&gt; in 2019 (now &lt;strong&gt;Ultraleap&lt;/strong&gt;) suggests there is still interest in developing &lt;strong&gt;touchless interaction technologies&lt;/strong&gt;. By combining Leap Motion&amp;rsquo;s gesture recognition technology with &lt;strong&gt;haptic feedback systems&lt;/strong&gt;, there is potential for future devices that offer more immersive and precise touchless experiences in &lt;strong&gt;healthcare&lt;/strong&gt;, &lt;strong&gt;industrial design&lt;/strong&gt;, or &lt;strong&gt;remote collaboration&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion
&lt;/h3&gt;&lt;p&gt;The Leap Motion Controller was a visionary product that failed to achieve widespread success due to a lack of compelling use cases, tracking issues, and insufficient developer support. However, with the growing demand for &lt;strong&gt;gesture-based interaction&lt;/strong&gt; in VR/AR environments, and the potential for improved accuracy through new technologies, the underlying concepts of Leap Motion may still play a key role in future human-computer interaction paradigms.&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Lecture 1 - Affordances</title>
        <link>http://localhost:1313/post/affordances/affordances/</link>
        <pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/affordances/affordances/</guid>
        <description>&lt;img src="http://localhost:1313/images/affordance.jpg" alt="Featured image of post Lecture 1 - Affordances" /&gt;&lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=https://medium.com/@akadiyala/role-of-affordances-in-digital-transformation-and-internet-of-things-fa2896970480 style=&#34;color: gray;&#34;&gt; Anant Kadiyala &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Affordance gives users a visual hint on what actions they can take.&lt;/p&gt;
&lt;p&gt;For example, when we see a button, we instinctively want to press it, or when we see a switch, we feel like pulling it. On an app or website, a rectangular box with a border makes us think we can click and type into it. These cues play into human psychology.&lt;/p&gt;
&lt;p&gt;Thus, affordance is a crucial element of visual user interfaces. The clearer the visual cues are, the less ambiguity there is for the user to understand what action is expected.&lt;/p&gt;
&lt;p&gt;In mobile environments, the importance of affordance becomes even more pronounced, as the small screen size and limited space make it harder for affordance to be as visually obvious. Therefore, clear affordance is critical to ensure smooth user interaction on mobile devices.&lt;/p&gt;
&lt;h2 id=&#34;good-case---traffic-lights-that-show-the-remaining-time&#34;&gt;Good case - Traffic lights that show the remaining time
&lt;/h2&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/trafficlight.jpg&#34; alt=&#34;Traffic light&#34; width=&#34;50%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://busan.fnnews.com/news/202004071520322481&#34; style=&#34;color: gray;&#34;&gt;Busan News&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1. Clear Information Display&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Traffic lights that show the remaining time provide users with clear information on how much time is left before the signal changes. Pedestrians can easily determine whether they have enough time to cross the street, and drivers can predict when the signal will switch. This intuitive display helps users make more informed and safer decisions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Behavior Guidance&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The countdown timer allows both pedestrians and drivers to act accordingly. Pedestrians can choose to cross quickly if there is enough time, or wait for the next signal if time is running out. This guides user behavior and enhances traffic safety by reducing risky actions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Meeting User Expectations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In addition to simply showing red or green lights, the countdown timer allows users to predict signal changes more accurately. This design meets user expectations by providing precise information, reducing stress at intersections, and improving overall traffic flow.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bad-case---keyboard&#34;&gt;Bad case - Keyboard
&lt;/h2&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/keyboard.jpg&#34; alt=&#34;Keyboard&#34; width=&#34;50%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: https://www.clien.net/service/board/park/16744923&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The placement of a power button above the delete key on a keyboard is a bad example of affordance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Risk of Accidental Use&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When the power button is located too close to the delete key, users are more likely to press it accidentally, potentially shutting down the system unintentionally. The functions are too distinct to be placed so closely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Functional Mismatch&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The delete key is frequently used, whereas the power button is not. Placing such an important function near a less frequently used key increases the risk of errors and reduces the overall usability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Contrary to User Expectations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users do not expect two very different functions to be positioned so closely together. This placement disrupts the intuitive understanding of how the keyboard should work.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solutions&#34;&gt;&lt;em&gt;Solutions&lt;/em&gt;
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. Relocate the Power Button&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The most straightforward solution is to move the power button to a location further away from frequently used keys like the delete key. For example, the power button could be placed at the right-top corner of the keyboard, near the function keys or in a separate, more isolated area where it’s less likely to be pressed by accident.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Add a Confirmation Step&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implementing a confirmation step when the power button is pressed would prevent accidental shutdowns. For instance, instead of instantly shutting down the system, the button could trigger a prompt asking the user to confirm the action.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Lecture 2 - Gestalt Law</title>
        <link>http://localhost:1313/post/gestalt-laws/gestaltlaw/</link>
        <pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/gestalt-laws/gestaltlaw/</guid>
        <description>&lt;img src="http://localhost:1313/images/gestalt.jpg" alt="Featured image of post Lecture 2 - Gestalt Law" /&gt;&lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://medium.com/ringcentral-ux/gestalt-principles-learn-how-to-influence-perception-83112932d0bc&#34; style=&#34;color: gray;&#34;&gt;Gestalt Principles&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gestalt&lt;/strong&gt; is a German word meaning &amp;lsquo;form&amp;rsquo; or &amp;lsquo;shape.&lt;/p&gt;
&lt;p&gt;It refers to how people perceive visual elements in a given situation. Generally, we compare visual patterns and past experiences to make sense of what we see. We often perceive these elements as a single whole, rather than as separate parts. By connecting the elements, recognizing familiar shapes, sharing information, and filling in the gaps, we make sense of the overall picture.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;1-law-of-proximity&#34;&gt;1. Law of Proximity
&lt;/h3&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/proximity.jpg&#34; alt=&#34;proximity&#34; width=&#34;70%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.toptal.com/designers/ui/gestalt-principles-of-design&#34; style=&#34;color: gray;&#34;&gt;By Cameron Chapman&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;Law of Proximity&lt;/strong&gt; descrives the phenomenon in which element that are close to each other are perceived and felt as a group.&lt;/p&gt;
&lt;p&gt;For example, in the left image, the dots don&amp;rsquo;t appear to be grouped. However, in the right image, the dots are closer together making them appear as three distinct groups. This &lt;strong&gt;proximity&lt;/strong&gt; can help in organizing related content by placing them close to each other.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-law-of-similarity&#34;&gt;2. Law of Similarity
&lt;/h3&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/similarity.jpg&#34; alt=&#34;similarity&#34; width=&#34;60%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.toptal.com/designers/ui/gestalt-principles-of-design&#34; style=&#34;color: gray;&#34;&gt;By Cameron Chapman&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;Law of Similarity&lt;/strong&gt; means that objects with similar shpes, sizes, colors, or other attributes are perceived as part of the same group.&lt;/p&gt;
&lt;p&gt;In this example, all shapes are squares, but the difference in color causes our brain to group the green squares together and the gray squares together, even though they share the same shape. This shows how color similarity plays a key role in organizing visual elements into groups.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;3-law-of-closure&#34;&gt;3. Law of Closure
&lt;/h3&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/closure.jpg&#34; alt=&#34;closure&#34; width=&#34;60%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.toptal.com/designers/ui/gestalt-principles-of-design&#34; style=&#34;color: gray;&#34;&gt;By Cameron Chapman&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;Law of Closure&lt;/strong&gt; refers to the tendency to perceive incomplete shapes as whole or complete. Our brain fills in the missing parts, allowing us to recognize an entire form even when elements are missing.&lt;/p&gt;
&lt;p&gt;In the image, some parts of the shapes are missing, but our brain automatically fills in the gaps, making us perceive the incomplete shapes as a complete form. This principle is commonly seen in logos or icons where parts of the design are missing, yet we still recognize the full shape.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;4-law-of-figure-ground&#34;&gt;4. Law of Figure-Ground
&lt;/h3&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/figureground.jpg&#34; alt=&#34;figure-ground&#34; width=&#34;60%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.toptal.com/designers/ui/gestalt-principles-of-design&#34; style=&#34;color: gray;&#34;&gt;By Cameron Chapman&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;Law of Figure-Ground&lt;/strong&gt; describes how we distinguish an object (the figure) from its surrounding background (the ground). Our focus shifts between the object and the background, depending on what we are focusing on at any given moment.&lt;/p&gt;
&lt;p&gt;In this image, depending on where we focus, we may see either the foreground shapes as the figure or the background. This principle is often used in visual illusions, where the brain toggles between seeing two different images depending on whether it focuses on the figure or the ground.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;5-law-of-continuity&#34;&gt;5. Law of Continuity
&lt;/h3&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/continuity.jpg&#34; alt=&#34;continutiy&#34; width=&#34;60%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.toptal.com/designers/ui/gestalt-principles-of-design&#34; style=&#34;color: gray;&#34;&gt;By Cameron Chapman&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;Law of Continuity&lt;/strong&gt; states that elements arranged on a line or curve are perceived as related or continuous. This principle explains how our eyes follow the smoothest path when interpreting visual elements.&lt;/p&gt;
&lt;p&gt;In this image, the red and gray dots form continuous curves. Even though they are separate dots, our brain perceives the curves as a single continuous path, demonstrating how continuity helps us organize visual elements in a flowing pattern.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;6-law-of-common-region&#34;&gt;6. Law of Common-region
&lt;/h3&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/commonregion.jpg&#34; alt=&#34;common-region&#34; width=&#34;60%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://app.uxcel.com/lessons/law-of-common-region-899&#34; style=&#34;color: gray;&#34;&gt;Uxcel&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;Law of Common-region&lt;/strong&gt; states that elements located within the same boundary are perceived as part of a group. A visual boundary such as a box or a color background can create this perception of grouping, even if the elements are not physically close.&lt;/p&gt;
&lt;p&gt;In this image, the circles inside the box are perceived as a group because they share a common region (the box). Even though the circles outside the box are the same size, shape, and color, they are seen as separate because they are not within the same boundary.&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;applications-of-gestalt-laws-in-daily-life&#34;&gt;Applications of Gestalt laws in daily life
&lt;/h1&gt;&lt;h2 id=&#34;1-confusing-stairs&#34;&gt;&lt;em&gt;1. Confusing stairs&lt;/em&gt;
&lt;/h2&gt;&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/gl_ex1.jpg&#34; alt=&#34;confusingstairs&#34; width=&#34;40%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://brightside.me/articles/15-designs-that-can-confuse-our-common-sense-809304/&#34; style=&#34;color: gray;&#34;&gt;Bright Side&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h3 id=&#34;problem&#34;&gt;Problem
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Law of Continuity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This pattern has consistent stripes, which causes our eyes to fail in distinguishing where the stairs end and begin, making the surface appear like a continuous plane. In situations where step differences need to be recognized, this pattern can create visual confusion, which poses a safety risk.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Law of Figure-Ground&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a lack of clear distinction between the figure (the stairs) and the background. As a result, it becomes harder to perceive the shape and depth of the stairs, and users may struggle to identify the height changes of the steps.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solution&#34;&gt;Solution
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Clear Boundary Markings&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adding a different colored stripe to the edges of each step can help clearly distinguish the boundary of the stairs. This will break the continuity and allow the steps to be seen as distinct units.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Enhancing Contrast&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To better separate the background and foreground, stronger color contrast can be applied to the steps. For example, using a brighter color on the edges of the stairs will help clearly define the steps, making it easier to perceive the changes in height.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-apple-recent-call&#34;&gt;&lt;em&gt;2. Apple Recent call&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/gl_ex2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;confusingstairs&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;problem-1&#34;&gt;Problem
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Law of Proximity&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In this interface, the name and the call action are perceived as a single unit or function because of how the interaction works (tapping on the name directly initiates a call.) Users expect tapping on the name to display contact details, but because the call action is implicitly tied to this tap, they accidentally initiate calls. The proximity of the name and the action (or the lack of distinction between the two actions) leads to confusion.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solution-1&#34;&gt;Solution
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Add a confirmation dialog&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After tapping a contact name, ask the user, &amp;ldquo;Do you want to make a call?&amp;rdquo; This would help prevent accidental calls.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Improve visual cues&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clearly distinguish the action of viewing contact details from initiating a call. For example, a separate button for calling that’s visually distinct from the contact&amp;rsquo;s name would better guide the user’s actions.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Lecture 3 - Dark Design Patterns</title>
        <link>http://localhost:1313/post/dark-design-patterns/darkdesignpattern/</link>
        <pubDate>Thu, 19 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/dark-design-patterns/darkdesignpattern/</guid>
        <description>&lt;img src="http://localhost:1313/images/darkpatterndesign.jpg" alt="Featured image of post Lecture 3 - Dark Design Patterns" /&gt;&lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://polytechnic.purdue.edu/newsroom/dark-patterns-user-experience-design-manipulates-consumers&#34; style=&#34;color: gray;&#34;&gt;By John O&#39;Malley &lt;/a&gt;&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/darkpattern.jpg&#34; alt=&#34;proximity&#34; width=&#34;70%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://uxknowledgebase.com/dark-patterns-3b41ed7a690e&#34; style=&#34;color: gray;&#34;&gt;By Krisztina Szerovay&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Dark patterns&lt;/strong&gt; are UI/UX design techniques intentionally crafted to exploit human psychology and trick users into doing things they don’t necessarily want to do. The British UX designer &lt;strong&gt;Harry Brignull&lt;/strong&gt;, who first coined the term, described dark patterns as follows&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“A carefully crafted user interface designed to trick users into performing actions such as signing up for insurance or signing up for recurring bills.”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, dark patterns refer to UI/UX that is cleverly and intentionally designed to elicit certain actions from users, whether they want to or not. These designs often serve business goals, such as increasing subscriptions or data collection, but they do so at the expense of the user’s autonomy, leading to unintended actions like accidental purchases or subscriptions.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;types-of-dark-patterns-design&#34;&gt;Types of Dark Patterns Design
&lt;/h3&gt;&lt;p&gt;Here are five types of dark patterns commonly seen&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Nagging&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/nagging.jpg&#34; alt=&#34;Nagging dark pattern example&#34; width=&#34;30%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.researchgate.net/figure/Example-of-nagging-behavior-on-Instagram-where-a-modal-dialogue-provides-no-opportunity_fig1_322916969&#34; style=&#34;color: gray;&#34;&gt;ResearchGate&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Nagging&lt;/strong&gt; occurs when an app or website repeatedly interrupts the user’s progress with prompts or messages, draining their time and attention. These interruptions can make the user feel pressured or annoyed, leading them to eventually agree to the message or request—even if it’s not what they want—just to move forward.&lt;/li&gt;
&lt;li&gt;If the interruptions happen frequently, the user might decide that giving in to the prompt is easier than continuing to dismiss it. This pattern is commonly seen in requests to subscribe to premium services, allow notifications, or share personal data, and it can result in a frustrating user experience.&lt;/li&gt;
&lt;/ul&gt;
 &lt;!--  
2. **Obstruction**

&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/obstruction.jpg&#34; alt=&#34;Obstruction dark pattern example&#34; width=&#34;50%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.deceptive.design/types/obstruction&#34; style=&#34;color: gray;&#34;&gt;Norwegian Consumer Council, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

- **Obstruction** involves intentionally making certain tasks difficult or confusing for the user. It artificially complicates the steps required to perform actions that the user might want to avoid, such as canceling a service, deleting an account, or disabling ads. Designers create complex menu structures, lengthy procedures, and multiple confirmation steps to increase the likelihood that the user will give up.
- For example, subscribing to a service may be as simple as one click, but canceling that same service might involve navigating through a series of confusing steps, or even contacting customer support. By increasing the effort required to complete the task, users are more likely to give up and continue their subscription, even if they originally intended to cancel.

3. **Sneaking**

&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/sneaking.jpg&#34; alt=&#34;Sneaking dark pattern example&#34; width=&#34;50%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://app.uxcel.com/lessons/dark-patterns-024&#34; style=&#34;color: gray;&#34;&gt;Uxcel&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

- **Sneaking** occurs when important information, such as additional fees or terms, is hidden from the user until the last possible moment. This pattern is often used to make a product or service appear cheaper or more attractive than it actually is, only revealing the true cost or consequences just before the user commits.

- For example, an e-commerce site may show an item at a discounted price, but hidden fees like taxes or shipping costs are only added at the checkout stage. This tactic leaves the user feeling deceived and frustrated because they weren’t provided with full transparency from the beginning.


4. **Interface Interference**

&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/nagging.jpg&#34; alt=&#34;Nagging dark pattern example&#34; width=&#34;30%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.researchgate.net/figure/Example-of-nagging-behavior-on-Instagram-where-a-modal-dialogue-provides-no-opportunity_fig1_322916969&#34; style=&#34;color: gray;&#34;&gt;ResearchGate&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

- **Interface** interference manipulates the design of user interface elements—such as buttons, links, or menus—to confuse or mislead the user. This could involve making certain options (like opting out or declining a service) difficult to see or access, or intentionally placing desired actions in locations where users are less likely to find them.

- A common example is when a “Subscribe” or “Accept” button is highlighted in bright colors, while the “No Thanks” or “Decline” option is either hidden or made to blend in with the background. This visual manipulation influences the user’s decision, making them more likely to choose the option that benefits the company.

5. **Forced Action**

&lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/images/nagging.jpg&#34; alt=&#34;Nagging dark pattern example&#34; width=&#34;30%&#34;&gt;
  &lt;p style=&#34;font-size: 12px; color: gray;&#34;&gt;Image Source: &lt;a href=&#34;https://www.researchgate.net/figure/Example-of-nagging-behavior-on-Instagram-where-a-modal-dialogue-provides-no-opportunity_fig1_322916969&#34; style=&#34;color: gray;&#34;&gt;ResearchGate&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

- **Forced Action** refers to situations where the user is required to perform a specific action in order to continue using a service or complete a task. This pattern typically forces users to agree to terms, share personal information, or sign up for a service they may not want, simply to proceed with what they were doing.

- For instance, a user might be required to create an account or subscribe to a newsletter before they can continue using a free app or access content. This design forces users to take an action they don’t necessarily want to take, making them feel trapped or cornered.


---
--&gt;</description>
        </item>
        
    </channel>
</rss>
